# PBICRL
_Preference-Based Bayesian Inverse Constraint Reinforcement Learning_ (PBICRL) is a Bayesian approach that infers constraints from demonstrations. The likelihood function is based on a modification of the Bradley-Terry model that allows it to compensate for different margins among the preferences.



# Requirements
The code was written in Python 3.8.13 \
To install the requirements: \
pip install -r requirements.txt

# Contents

Each folder contains the code for the four simulation environments used in the paper. You can run the code by simply running run_experiments.sh.



<!---

## Point-Mass
# References

If you find this paper interesting and relevant to your work you can cite it as follows:

@article{papadimitriou2022bayesian,\
title={Bayesian Methods for Constraint Inference in Reinforcement Learning},\
author={Papadimitriou, Dimitris and Anwar, Usman and Brown, Daniel S.},\
journal={Transactions on Machine Learning Research},\
year={2022},\
url={https://openreview.net/forum?id=oRjk5V9eDp }
}
--->
